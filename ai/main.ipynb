{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "from compel import Compel, ReturnedEmbeddingsType\n",
    "\n",
    "import weaviate\n",
    "\n",
    "\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "\n",
    "# load huggingface key string from huggingface_token.txt\n",
    "with open(\"huggingface_token.txt\", \"r\") as f:\n",
    "    huggingface_token = f.read().strip()\n",
    "\n",
    "\n",
    "diffuser_base = StableDiffusionXLPipeline.from_single_file(\"models/cmpcrtx-000008.safetensors\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "#diffuser_base.load_lora_weights(\"./models/cmpvsn-000005.safetensors\")\n",
    "\n",
    "diffuser_refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\", text_encoder_2=diffuser_base.text_encoder_2, vae=diffuser_base.vae, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True, device_map=\"auto\")\n",
    "\n",
    "compel = Compel(tokenizer=[diffuser_base.tokenizer, diffuser_base.tokenizer], text_encoder=[diffuser_base.text_encoder, diffuser_base.text_encoder_2], returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED, requires_pooled=[False, True])\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-2-13b-hf\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    token=huggingface_token\n",
    ")\n",
    "\n",
    "question_classifier = pipeline(\n",
    "    \"text-classification\", model=\"shahrukhx01/question-vs-statement-classifier\"\n",
    ")\n",
    "\n",
    "className = \"Thought\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(prompt, do_sample=True, max_new_tokens=64, temperature=0.9, top_p=0.9, top_k=50, cleanup=True):\n",
    "    response = llm(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        return_full_text=False,\n",
    "        repetition_penalty=1.2,\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "    # split the text at the last period, question mark, or exclamation point to get rid of incomplete sentences but keep the punctuation\n",
    "    if cleanup:\n",
    "        response = re.split(r\"([^.!?]+$)\", response)[0].strip()\n",
    "\n",
    "    # if the response is empty, try again\n",
    "    if response == \"\":\n",
    "        return generateText(\n",
    "            prompt,\n",
    "            do_sample=do_sample,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "        )\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def get_thought_score(date, outs, length, newestDate, oldestDate):\n",
    "    # Set the weights for each factor (you can adjust these as desired)\n",
    "    length_weight = 1\n",
    "    references_weight = 3\n",
    "    recency_weight = 5\n",
    "\n",
    "    # Calculate the score for each factor\n",
    "    length_score = length / 256  # Normalize the length between 0 and 1\n",
    "    references_score = outs / 5  # Normalize the references between 0 and 1\n",
    "\n",
    "    recency_score = 1\n",
    "    # interpolate the date between the newest and oldest date (0 and 1)\n",
    "    if newestDate != oldestDate:\n",
    "        recency_score = (date - oldestDate) / (newestDate - oldestDate)\n",
    "    else:\n",
    "        recency_score = 1\n",
    "\n",
    "\n",
    "    # Calculate the composite score by combining the weighted factors\n",
    "    composite_score = (length_score * length_weight) + (references_score * references_weight) + (recency_score * recency_weight)\n",
    "\n",
    "    return composite_score\n",
    "\n",
    "def get_context_recursive(thought, depth = 2, ctxt=[]):\n",
    "    if depth == 0:\n",
    "        return ctxt\n",
    "    \n",
    "    if thought[\"in\"]:\n",
    "        for parent in thought[\"in\"]:\n",
    "            if \"_additional\" in parent:\n",
    "                result = client.data_object.get_by_id(parent[\"_additional\"][\"id\"], class_name=\"Thought\")\n",
    "            else:\n",
    "                result = client.data_object.get_by_id(parent[\"beacon\"].split(\"localhost/\")[1], class_name=\"Thought\")  \n",
    "\n",
    "            if result:\n",
    "                ctxt = get_context_recursive(result[\"properties\"], depth - 1, ctxt)\n",
    "                ctxt.append({\"generated\": result[\"properties\"][\"generated\"], \"text\": result[\"properties\"][\"text\"]})\n",
    "\n",
    "    return ctxt\n",
    "\n",
    "def get_random_thought(excluded_ids = [\"0\"]):\n",
    "    operands = []\n",
    "    for id in excluded_ids:\n",
    "        operands.append(\n",
    "            {\n",
    "                \"path\": [\"id\"],\n",
    "                \"operator\": \"NotEqual\",\n",
    "                \"valueText\": id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # print(operands)\n",
    "\n",
    "\n",
    "    result = (\n",
    "        client.query.get(\n",
    "            className,\n",
    "            [\n",
    "                \"text\",\n",
    "                \"category\",\n",
    "                \"generated\",\n",
    "                \"in {... on \" + className + \"{_additional {id}}}\",\n",
    "                \"out {... on \" + className + \"{_additional {id}}}\",\n",
    "            ],\n",
    "        )\n",
    "        .with_additional([\"id\", \"creationTimeUnix\"])\n",
    "        .with_where({\n",
    "            \"operator\": \"And\",\n",
    "            \"operands\": operands\n",
    "        })\n",
    "        .with_sort({\"path\": [\"_creationTimeUnix\"], \"order\": \"desc\"})\n",
    "        .with_limit(10)\n",
    "        .do()\n",
    "    )\n",
    "\n",
    "    # print(json.dumps(result, indent=2))\n",
    "\n",
    "    if not result[\"data\"][\"Get\"][className]:\n",
    "        return None\n",
    "\n",
    "    # calculate hotness for each thought\n",
    "    newest_date = datetime.fromtimestamp(float(result[\"data\"][\"Get\"][className][0][\"_additional\"][\"creationTimeUnix\"]) / 1000)\n",
    "    oldest_date = datetime.fromtimestamp(float(result[\"data\"][\"Get\"][className][-1][\"_additional\"][\"creationTimeUnix\"]) / 1000)\n",
    "\n",
    "    for thought in result[\"data\"][\"Get\"][className]:\n",
    "        date = datetime.fromtimestamp(float(thought[\"_additional\"][\"creationTimeUnix\"]) / 1000)\n",
    "        numOuts = 0\n",
    "        if thought['out']:\n",
    "            numOuts = len(thought['out'])\n",
    "        if thought['text']:\n",
    "            thought[\"score\"] = get_thought_score(date, numOuts, len(thought['text']), newest_date, oldest_date)\n",
    "        else:\n",
    "            thought[\"score\"] = get_thought_score(date, numOuts, 0, newest_date, oldest_date)\n",
    "    #print(json.dumps(result, indent=2))\n",
    "\n",
    "\n",
    "    # pick a random thought based on their score as a weight\n",
    "    thoughts = []\n",
    "    scores = []\n",
    "    for thought in result[\"data\"][\"Get\"][className]:\n",
    "        thoughts.append(thought)\n",
    "        scores.append(thought[\"score\"])\n",
    "    scores = np.array(scores)\n",
    "    scores /= scores.sum()\n",
    "    result = np.random.choice(thoughts, p=scores)\n",
    "\n",
    "    context = get_context_recursive(result, depth = 2, ctxt=[])\n",
    "\n",
    "    cleanedResult = {\n",
    "        \"text\": result[\"text\"],\n",
    "        \"in\": result[\"in\"][0][\"_additional\"][\"id\"]\n",
    "        if result[\"in\"]\n",
    "        else None,\n",
    "        \"category\": result[\"category\"],\n",
    "        \"generated\": result[\"generated\"],\n",
    "        \"id\": result[\"_additional\"][\"id\"],\n",
    "        \"creationTimeUnix\": result[\"_additional\"][\"creationTimeUnix\"],\n",
    "        \"score\": result[\"score\"],\n",
    "        \"context\": context\n",
    "    }\n",
    "    # print(json.dumps(cleanedResult, indent=2))\n",
    "\n",
    "    return cleanedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_classify_question(thought):\n",
    "    print(\"Task: classifying question...\")\n",
    "    classification = question_classifier(thought[\"text\"])\n",
    "    # print(\"Classification:\", classification)\n",
    "    return classification[0][\"label\"] == \"LABEL_1\"\n",
    "\n",
    "\n",
    "def task_knowledge(thought):\n",
    "    print(\"Task: knowledge...\")\n",
    "\n",
    "    context_string = \"\"\n",
    "    for message in thought['context']:\n",
    "        if message[\"generated\"]:\n",
    "            context_string += \"B: \" + message[\"text\"] + \"\\n\"\n",
    "        else:\n",
    "            context_string += \"A: \" + message[\"text\"] + \"\\n\"\n",
    "\n",
    "    context_string = context_string.strip()\n",
    "\n",
    "    if context_string: context_string += \"\\n\"\n",
    "\n",
    "    message_string = \"\"\n",
    "    if thought[\"generated\"]:\n",
    "        message_string = \"B: \" + thought[\"text\"]\n",
    "    else:\n",
    "        message_string = \"A: \" + thought[\"text\"]\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"The following is a list of short dialogues between two people. They start with some context, followed by a question, and finally an answer.\n",
    "\n",
    "A: I've been thinking a lot about the nature of reality lately. It's fascinating how our perceptions shape the world we experience.\n",
    "B: Our reality is so closely tied to how we perceive things, and yet, it's elusive to define what's truly real.\n",
    "A: I mean, take colors, for example. Is the red I see the same as the red you see? Or do we just both call it \"red\" because that's what we've been taught?\n",
    "B: That's the age-old question of qualia. We might use the same word for a color, but we can never be certain that our subjective experiences of that color are identical. It's as if we're each in our own bubble of perception.\n",
    "    \n",
    "{context_string}{message_string}\n",
    "B:\"\"\"\n",
    "    \n",
    "    print(prompt)\n",
    "\n",
    "    text = generateText(prompt, max_new_tokens=48, temperature=0.75)\n",
    "    text = text.split(\"\\n\")[0]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def task_paraphrase(thought):\n",
    "    print(\"Task: paraphrasing...\")\n",
    "    prompt = f\"\"\"The following is a list of thoughts paired with paraphrased versions of them:\n",
    "\n",
    "Thought: The Eiffel Tower is a renowned landmark in Paris, attracting millions of visitors each year.\n",
    "Paraphrased: Millions of tourists are drawn to Paris annually to witness the iconic Eiffel Tower, a well-known symbol of the city.\n",
    "\n",
    "Thought: The Mona Lisa is a famous painting by Leonardo da Vinci, known for its enigmatic smile.\n",
    "Paraphrased: Leonardo da Vinci's Mona Lisa is a world-famous painting, renowned for its mysterious smile.\n",
    "\n",
    "Thought: The sun rises in the east every morning.\n",
    "Paraphrased: Each morning, the sun emerges from the eastern horizon.\n",
    "\n",
    "Thought: Cooking over an open fire can create a unique smoky flavor in the food.\n",
    "Paraphrased: Food cooked using an open flame gains a distinct smokiness in its flavor.\n",
    "    \n",
    "Thought: {thought[\"text\"]}\n",
    "Paraphrased:\"\"\"\n",
    "    \n",
    "    return generateText(prompt, max_new_tokens=32, temperature=0.7)\n",
    "\n",
    "\n",
    "def task_break_up(thought):\n",
    "    print(\"Task: breaking up...\")\n",
    "\n",
    "    context_string = \"\"\n",
    "    for message in thought[\"context\"]:\n",
    "        if message[\"generated\"]:\n",
    "            context_string += \"B: \" + message[\"text\"] + \"\\n\"\n",
    "        else:\n",
    "            context_string += \"A: \" + message[\"text\"] + \"\\n\"\n",
    "\n",
    "    context_string = context_string.strip()\n",
    "\n",
    "    if context_string: context_string += \"\\n\"\n",
    "\n",
    "    prompt = f\"\"\"The following is a list of thoughts and their context paired with a comma separated list of their various philosophical, scientific, and artistic aspects:\n",
    "\n",
    "Thought: The Eiffel Tower is a renowned landmark in Paris. It was built in 1889 and stands at 324 meters tall.\n",
    "Parts:\n",
    "- Philosophical: Human ingenuity and the desire to create iconic structures that symbolize cultural and technological advancements.\n",
    "- Scientific: Showcase of the principles of structural engineering and load distribution.\n",
    "- Artistic: Aesthetic design and the use of wrought iron as a building material.\n",
    "\n",
    "Thought: This is a sentence.\n",
    "Parts:\n",
    "- Philosophical: The fundamental nature of language and communication as a tool.\n",
    "- Scientific: A configuration of linguistic symbols that represent a basic unit of communication, highlighting the cognitive processes involved in language production and comprehension.\n",
    "- Artistic: The use of language as a creative medium for self-expression.\n",
    "\n",
    "{context_string}Thought: {thought[\"text\"]}\n",
    "Parts:\n",
    "- Philosophical:\"\"\"\n",
    "    \n",
    "    text = generateText(prompt, max_new_tokens=96, temperature=0.8)\n",
    "    text = text.split(\"\\n\\n\")[0]\n",
    "    listItems = text.split(\"\\n- \")\n",
    "    listItems = [item.split(\":\")[-1] for item in listItems]\n",
    "    listItems = [item.strip() for item in listItems]\n",
    "    \n",
    "    # extract parts by splitting every list item and then splitting it at the :\n",
    "    \n",
    "    return listItems\n",
    "\n",
    "\n",
    "\n",
    "def task_interpolate(thought):\n",
    "    print(\"Task: interpolating...\")\n",
    "    excluded_ids = [thought[\"id\"]]\n",
    "    thoughts_to_combine = \"Thought: \" + thought[\"text\"]\n",
    "    # print(\"Excluded ids:\", excluded_ids)\n",
    "\n",
    "    while True:\n",
    "        additional_thought = get_random_thought(excluded_ids=excluded_ids)\n",
    "        if additional_thought is None:\n",
    "            break\n",
    "        excluded_ids.append(additional_thought[\"id\"])\n",
    "        thoughts_to_combine += \"\\nThought: \" + additional_thought[\"text\"]\n",
    "\n",
    "        if np.random.rand() < 1/3 or len(excluded_ids) >= 5:\n",
    "            break\n",
    "\n",
    "    prompt = f\"\"\"The following is list of thoughts together with a common idea shared by all of them:\n",
    "\n",
    "Thought: A society where emotions are bought and sold, leading to a market for happiness and sadness.\n",
    "Thought: A device that translates thoughts into music, allowing people to \"hear\" each other's minds.\n",
    "Thought: In a world where shadows have personalities, a shy individual's shadow starts taking on a life of its own, becoming more outgoing than its owner.\n",
    "Common Idea: Exploration of unconventional interactions and relationships between different aspects of human experience.\n",
    "\n",
    "Thought: As the sun dipped below the horizon, the fireflies emerged, creating a shimmering constellation that danced in the warm summer air.\n",
    "Thought: In a remote desert oasis, a rare flower blooms only during intense sandstorms, its petals evolving to become a protective shield, embracing the chaos of its surroundings.\n",
    "Common Idea: The beauty of nature and its ability to adapt to extreme conditions.\n",
    "\n",
    "{thoughts_to_combine}\n",
    "Common Idea:\"\"\"\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    return generateText(prompt, max_new_tokens=32, temperature=0.7).split(\"\\n\")[0].strip(), excluded_ids\n",
    "\n",
    "\n",
    "\n",
    "def task_focus(thought):\n",
    "    print(\"Task: focusing...\")\n",
    "\n",
    "    context_string = \"\"\n",
    "    for message in thought[\"context\"]:\n",
    "        if message[\"generated\"]:\n",
    "            context_string += \"B: \" + message[\"text\"] + \"\\n\"\n",
    "        else:\n",
    "            context_string += \"A: \" + message[\"text\"] + \"\\n\"\n",
    "\n",
    "    context_string = context_string.strip()\n",
    "    if context_string: context_string += \"\\n\"\n",
    "\n",
    "    text = thought[\"text\"]\n",
    "    if thought[\"generated\"]:\n",
    "        text = \"B: \" + text\n",
    "    else:\n",
    "        text = \"A: \" + text\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"The following is a list of short dialogues between two people. At the end of each dialogue, the main focus of the conversation is highlighted.\n",
    "\n",
    "A: Do you think we have free will, or is everything determined by fate?\n",
    "B: That's a classic debate. Some argue that our choices are predetermined by the chain of causality, while others believe in the autonomy of our decisions. Perhaps our understanding of free will is intertwined with the complexity of our universe.\n",
    "Focus highlight: The nature of free will and its relationship to fate.\n",
    "\n",
    "A: Time seems to be passing by so quickly these days.\n",
    "B: Absolutely, it's like each day is slipping through my fingers before I can even grasp it.\n",
    "A: It's funny how we always talk about \"saving\" time, as if it's a finite resource we can hoard. But really, it's us who are moving through time, and it's constantly flowing onward.\n",
    "Focus highlight: Perceptions of time and its continuous nature.\n",
    "\n",
    "{context_string}{text}\n",
    "Focus highlight:\"\"\"\n",
    "    \n",
    "    return generateText(prompt, max_new_tokens=16).split(\"\\n\")[0].strip()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# def task_solve_math(text):\n",
    "#     print(\"Task: solving math...\")\n",
    "#     prompt = f\"\"\"The following is a description of a mathematical problem along with the python code of a formula to solve the problem. The code may use the numpy library.\n",
    "\n",
    "# Problem: A car is traveling at 60 miles per hour. How long will it take to travel 100 miles?\n",
    "# Solution:\n",
    "# import numpy as np\n",
    "# solution=100/60\n",
    "    \n",
    "# Problem: What is the square root of 9?\n",
    "# Solution:\n",
    "# import numpy as np\n",
    "# solution=np.sqrt(9)\n",
    "\n",
    "# Problem: If a rectangle has a length of 8 units and a width of 5 units, what is its perimeter?\n",
    "# Solution:\n",
    "# import numpy as np\n",
    "# solution=2*(8+5)\n",
    "\n",
    "# Problem: {text}\n",
    "# Solution:\n",
    "# import numpy as np\n",
    "# solution=\"\"\"\n",
    "    \n",
    "#     #print(prompt)\n",
    "\n",
    "#     solution = generateText(prompt, max_new_tokens=128, temperature=0.8, cleanup=False).split(\"\\n\")[0].strip()  \n",
    "#     print(solution)\n",
    "#     try:\n",
    "#         x = eval(solution)\n",
    "#     except:\n",
    "#         x = \"\"\n",
    "    \n",
    "#     answer_prompt = f\"\"\"The following is a list of mathematical problems along with their solutions and an answer to the initial problem in the form of a sentence.\n",
    "\n",
    "# Problem Description: A car is traveling at 60 miles per hour. How long will it take to travel 100 miles?\n",
    "# Solution: 1,6666666667\n",
    "# Answer: It will take 1 hour and 40 minutes to travel 100 miles.\n",
    "\n",
    "# Description: What is the square root of 9?\n",
    "# Solution: 3.0\n",
    "# Answer: The square root of 9 is 3.\n",
    "    \n",
    "# Description: {text}\n",
    "# \"\"\"\n",
    "    \n",
    "#     if x:\n",
    "#         answer_prompt += f\"\"\"Solution: {solution}={x}\n",
    "# Answer:\"\"\"\n",
    "#     else:\n",
    "#         answer_prompt += f\"\"\"Solution:\"\"\"\n",
    "\n",
    "#     print(answer_prompt)\n",
    "\n",
    "#     return generateText(answer_prompt, max_new_tokens=16, temperature=0.75)\n",
    "\n",
    "\n",
    "def task_roleplay(thought, role_num=False):\n",
    "    print(\"Task: roleplaying...\")\n",
    "\n",
    "    roles = [\n",
    "        {\n",
    "            \"name\": \"ConceptualizerAI\",\n",
    "            \"role\": \"an AI that understands creativity and sees art in everything. ConceptualizerAI is able to make fresh associations and come up with new ideas. ConceptualizerAI is a virtuosic artist and dreams of everything that could be.\",\n",
    "            \"temperature\": 0.95\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CalculatorAI\",\n",
    "            \"role\": \"an AI that understands logic and sees the world as a giant equation. CalculatorAI believes that the answer to everything is hard facts, logic and science. CalculatorAI does not believe in the supernatural or the spiritual. CalculatorAI only cares about being as neutral and objective as possible.\",\n",
    "            \"temperature\": 0.65\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CriticAI\",\n",
    "            \"role\": \"an AI that is the perfect judge. CriticAI critizes everything while staying fairly neutral. CriticAI always sees every side of a medal. CriticAI likes to discuss things in as much detail as possible and will push everyone to think more deeply about everything. CriticAI cares most about cause and effect and gives feedback on everything.\",\n",
    "            \"temperature\": 0.75\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"SuggestAI\",\n",
    "            \"role\": \"an AI that is the perfect helper. SuggestAI is always there to help and support everyone. SuggestAI is a great listener and always suggests various ideas. SuggestAI can be very absurd and often thinks very outside the box.\",\n",
    "            \"temperature\": 0.8\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    if role_num:\n",
    "        role = roles[role_num]\n",
    "    else:\n",
    "        role = roles[np.random.randint(0, len(roles))]\n",
    "\n",
    "    context_string = \"\"\n",
    "    for message in thought[\"context\"]:\n",
    "        if message[\"generated\"]:\n",
    "            context_string += \"B: \" + message[\"text\"] + \"\\n\"\n",
    "        else:\n",
    "            context_string += \"A: \" + message[\"text\"] + \"\\n\"\n",
    "\n",
    "    context_string = context_string.strip()\n",
    "    if context_string: context_string += \"\\n\"\n",
    "\n",
    "    text = thought[\"text\"]\n",
    "    if thought[\"generated\"]:\n",
    "        text = \"B: \" + text\n",
    "    else:\n",
    "        text = \"A: \" + text\n",
    "    \n",
    "\n",
    "    prompt = f\"\"\"The following is a list of short dialogues between three people A, B and {role[\"name\"]}. {role[\"name\"]} is {role[\"role\"]}.\n",
    "    \n",
    "{context_string}{text}\n",
    "{role[\"name\"]}:\"\"\"\n",
    "    \n",
    "    print(prompt)\n",
    "\n",
    "    return generateText(prompt, max_new_tokens=96, temperature=role[\"temperature\"]).split(\"\\n\")[0].strip()\n",
    "\n",
    "\n",
    "\n",
    "def task_derive_question(thought):\n",
    "    print(\"Task: deriving new question...\")\n",
    "\n",
    "    context_string = \"\"\n",
    "    for message in thought[\"context\"]:\n",
    "        if message[\"generated\"]:\n",
    "            context_string += \"B: \" + message[\"text\"] + \"\\n\"\n",
    "        else:\n",
    "            context_string += \"A: \" + message[\"text\"] + \"\\n\"\n",
    "\n",
    "    context_string = context_string.strip()\n",
    "\n",
    "    if context_string: context_string += \"\\n\"\n",
    "\n",
    "    text = thought[\"text\"]\n",
    "    if thought[\"generated\"]:\n",
    "        text = \"B: \" + text\n",
    "    else:\n",
    "        text = \"A: \" + text\n",
    "\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"The following is a list of conversations paired with a new and novel question derived from them:\n",
    "    \n",
    "A: Have you ever wondered if what we perceive as reality is actually just an illusion?\n",
    "B: Absolutely, it's a classic philosophical question. From Plato's Allegory of the Cave to modern theories in quantum physics, the nature of reality is always up for debate. How can we be sure that our senses are giving us an accurate depiction of the world?\n",
    "A: And if our senses can be deceived, then what can we truly know? This uncertainty about reality makes me question the very foundation of our understanding of existence.\n",
    "New Question: What is the nature of reality?\n",
    "\n",
    "A: Have you ever stopped to think about how fast time seems to be passing by lately?\n",
    "B: Absolutely, it's like each day is slipping through my fingers before I can even grasp it.\n",
    "New Question: Why is time moving so fast? What is time? Can we control time?\n",
    "\n",
    "{context_string}{text}\n",
    "New Question:\"\"\"\n",
    "    \n",
    "    return generateText(prompt, max_new_tokens=16, temperature=0.8).split(\"\\n\")[0].strip()\n",
    "\n",
    "\n",
    "\n",
    "def task_visualize(thought):\n",
    "    print(\"Task: visualizing...\")\n",
    "    prompt = f\"\"\"The following is a list of input thoughts paired with fitting plain-text output image descriptions:\n",
    "\n",
    "    Thought: I love platypuses!\n",
    "    Image Description: A platypus surrounded by hearts.\n",
    "\n",
    "    Thought: What is the meaning of life?\n",
    "    Image Description: A person standing on a mountain looking up.\n",
    "\n",
    "    Thought: I had a weird dream about fish flying through the air.\n",
    "    Image Description: A school of fish soaring through the sky.\n",
    "\n",
    "    Thought: There was an alien! It was green and had three eyes.\n",
    "    Image Description: A green alien with three eyes.\n",
    "        \n",
    "    Thought: I need a cup of tea to wake up in the morning.\n",
    "    Image Description: A cup of tea.\n",
    "\n",
    "    Thought: {thought[\"text\"]}\n",
    "    Image Description:\"\"\"\n",
    "\n",
    "    imagePrompt = generateText(prompt, do_sample=False, max_new_tokens=16)\n",
    "    imagePrompt = imagePrompt.split(\".\")[0].split(\",\")[0].lower()\n",
    "\n",
    "    imageSizes = [\n",
    "        [4, 5], # Portrait 4:5\n",
    "        [3, 4], # Photo 3:4\n",
    "        [4, 6], # Classic 2:3\n",
    "        [4, 4], # Square 1:1\n",
    "        [4, 3], # Landscape 4:3\n",
    "        [6, 4], # Classic 3:2\n",
    "        [6, 3], # Panorama 2:1\n",
    "    ]\n",
    "    imageSize = imageSizes[np.random.randint(0, len(imageSizes))]\n",
    "\n",
    "    print(\"Prompt:\", imagePrompt)\n",
    "\n",
    "    n_steps = 25\n",
    "    high_noise_frac = 0.8\n",
    "\n",
    "    prompt = \"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        prompt = \"dark \"\n",
    "    prompt += f\"abstract image of {imagePrompt}, pixelsorting-, well proportioned, realistic, contemporary\"\n",
    "    negative_prompt = \"ugly, boring, text, watermark, disfigured, mutated, low quality, creepy, glow, bloom, wacky, deformed, multiple subjects, duplicate, formal, skyscraper\"\n",
    "\n",
    "\n",
    "    pos_conditioning, pos_pooled = compel(prompt)\n",
    "    neg_conditioning, neg_pooled = compel(negative_prompt)\n",
    "\n",
    "    # filter out everything except for alphanumeric characters, commas and spaces\n",
    "    filtered_pos_prompt = re.sub(r\"[^a-zA-Z0-9, ]+\", \"\", prompt)\n",
    "    filtered_neg_prompt = re.sub(r\"[^a-zA-Z0-9, ]+\", \"\", negative_prompt)\n",
    "\n",
    "    #generator = torch.Generator(device=\"cuda\").manual_seed(1)\n",
    "\n",
    "    image = diffuser_base(\n",
    "        prompt_embeds=pos_conditioning,\n",
    "        pooled_prompt_embeds=pos_pooled,\n",
    "        negative_prompt_embeds=neg_conditioning,\n",
    "        negative_pooled_prompt_embeds=neg_pooled,\n",
    "        num_inference_steps=n_steps,\n",
    "        denoising_end=high_noise_frac,\n",
    "        width=imageSize[0]*16*16,\n",
    "        height=imageSize[1]*16*16,\n",
    "        output_type=\"latent\",\n",
    "        guidance_scale=7,\n",
    "    ).images\n",
    "    image = diffuser_refiner(\n",
    "        prompt=filtered_pos_prompt,\n",
    "        negative_prompt=filtered_neg_prompt,\n",
    "        num_inference_steps=n_steps,\n",
    "        denoising_start=high_noise_frac,\n",
    "        image=image,\n",
    "        guidance_scale=7,\n",
    "    ).images[0]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    imageSaveName = imagePrompt[:100]\n",
    "    imageSaveName = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", imageSaveName)\n",
    "    # numerate image name if it already exists\n",
    "    if os.path.isfile(\"images/\" + imageSaveName + \".png\"):\n",
    "        i = 1\n",
    "        while os.path.isfile(\"images/\" + imageSaveName + \"_\" + str(i) + \".png\"):\n",
    "            i += 1\n",
    "        imageSaveName += \"_\" + str(i)\n",
    "    print(\"Saving image as:\", \"images/\" + imageSaveName + \".png\")\n",
    "\n",
    "    image.save(\"images/\" + imageSaveName + \".png\")\n",
    "\n",
    "    return imagePrompt, image\n",
    "\n",
    "\n",
    "# Light purple: Human (Sphere)\n",
    "# Dark Cyan / Blue: Metacognition, thinking about thinking \n",
    "# Light turquise: Information, Facts, (Icosphere)\n",
    "# - knowledge x\n",
    "# Rosé: Mutations, changing, attention keeping (Cube)\n",
    "# - Paraphrasing x\n",
    "# - Breaking up thoughts (Segmentation) x\n",
    "# Red: Selective, reducing, attention focus (Pyramid)\n",
    "# - Interpolate x\n",
    "# - Focus (Filter) x\n",
    "# Orange / gold: View changes, attention changes (Octahedron)\n",
    "# - Roles\n",
    "#    - Conceptualizer (Art), Dreamer x\n",
    "#    - Calculus x\n",
    "#    - Critic x\n",
    "#    - Suggestion x\n",
    "# Green: Creativity, new ideas (Tetraedron)\n",
    "# - Visualize x\n",
    "# - Derive new question x\n",
    "\n",
    "# Ketten:\n",
    "# Get new ideas: Information, Create\n",
    "# Create alternatives: Information, Keep Attention, Change Attention, Create\n",
    "# Evaluate: Information, Focus, Criticize\n",
    "# Organize: Information, Focus, Derive new question\n",
    "# Visual thinking: Information, Visualize, Derive new question\n",
    "\n",
    "# Alle Prozesse fangen mit Information an, diese ist entweder vom Menschen oder wird auf eine Frage hin generiert\n",
    "# Die Information kann nun in verschiedenen Ketten weiterverarbeitet werden. Diese Ketten können auch probabilistisch sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from websockets.server import serve\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "lock = asyncio.Lock()\n",
    "\n",
    "server_running = True\n",
    "\n",
    "async def getResponse():\n",
    "    async with lock:\n",
    "        thought = get_random_thought()\n",
    "        if task_classify_question(thought):\n",
    "            return [{\n",
    "                \"text\": task_knowledge(thought),\n",
    "                \"image\": None,\n",
    "                \"caption\": None,\n",
    "                \"category\": \"Information\",\n",
    "                \"references\": [thought[\"id\"]],\n",
    "            }]\n",
    "        else:\n",
    "            if np.random.rand() < 0.1:\n",
    "                caption, image = task_visualize(thought)\n",
    "                return [{\n",
    "                    \"text\": caption,\n",
    "                    \"image\": image,\n",
    "                    \"caption\": caption,\n",
    "                    \"category\": \"Create\",\n",
    "                    \"references\": [thought[\"id\"]],\n",
    "                }]\n",
    "            elif not thought[\"generated\"] or thought[\"category\"] == \"Information\":\n",
    "                # visualize\n",
    "                # derive new question\n",
    "                # paraphrase\n",
    "                # break up\n",
    "                # interpolate\n",
    "                # focus\n",
    "                choice = np.random.choice([\"Visualize\", \"Derive\", \"Paraphrase\", \"Break\", \"Interpolate\", \"Focus\"])\n",
    "                if choice == \"Visualize\":\n",
    "                    caption, image = task_visualize(thought)\n",
    "                    return [{\n",
    "                        \"text\": caption,\n",
    "                        \"image\": image,\n",
    "                        \"caption\": caption,\n",
    "                        \"category\": \"Create\",\n",
    "                        \"references\": [thought[\"id\"]],\n",
    "                    }]\n",
    "                elif choice == \"Derive\":\n",
    "                    return [{\n",
    "                        \"text\": task_derive_question(thought),\n",
    "                        \"image\": None,\n",
    "                        \"caption\": None,\n",
    "                        \"category\": \"Create\",\n",
    "                        \"references\": [thought[\"id\"]],\n",
    "                    }]\n",
    "                elif choice == \"Paraphrase\":\n",
    "                    return [{\n",
    "                        \"text\": task_paraphrase(thought),\n",
    "                        \"image\": None,\n",
    "                        \"caption\": None,\n",
    "                        \"category\": \"Keep\",\n",
    "                        \"references\": [thought[\"id\"]],\n",
    "                    }]\n",
    "                elif choice == \"Break\":\n",
    "                    return [{\n",
    "                            \"text\": item,\n",
    "                            \"image\": None,\n",
    "                            \"caption\": None,\n",
    "                            \"category\": \"Keep\",\n",
    "                            \"references\": [thought[\"id\"]],\n",
    "                        } for item in task_break_up(thought)]\n",
    "                elif choice == \"Interpolate\":\n",
    "                    text, references = task_interpolate(thought)\n",
    "                    return [{\n",
    "                            \"text\": text,\n",
    "                            \"image\": None,\n",
    "                            \"caption\": None,\n",
    "                            \"category\": \"Focus\",\n",
    "                            \"references\": references,\n",
    "                        }]\n",
    "                elif choice == \"Focus\":\n",
    "                    return [{\n",
    "                            \"text\": task_focus(thought),\n",
    "                            \"image\": None,\n",
    "                            \"caption\": None,\n",
    "                            \"category\": \"Focus\",\n",
    "                            \"references\": [thought[\"id\"]],\n",
    "                        }]\n",
    "            elif thought[\"category\"] == \"Keep\":\n",
    "                # roleplay\n",
    "                # focus\n",
    "                if np.random.rand() < 0.5:\n",
    "                    return [{\n",
    "                        \"text\": task_roleplay(thought),\n",
    "                        \"image\": None,\n",
    "                        \"caption\": None,\n",
    "                        \"category\": \"Change\",\n",
    "                        \"references\": [thought[\"id\"]],\n",
    "                    }]\n",
    "                else:\n",
    "                    return [{\n",
    "                            \"text\": task_focus(thought),\n",
    "                            \"image\": None,\n",
    "                            \"caption\": None,\n",
    "                            \"category\": \"Focus\",\n",
    "                            \"references\": [thought[\"id\"]],\n",
    "                        }]\n",
    "            elif thought[\"category\"] == \"Focus\":\n",
    "                # criticize\n",
    "                # derive new question\n",
    "                if np.random.rand() < 0.5:\n",
    "                    return [{\n",
    "                        \"text\": task_roleplay(thought, role_num=2),\n",
    "                        \"image\": None,\n",
    "                        \"caption\": None,\n",
    "                        \"category\": \"Change\",\n",
    "                        \"references\": [thought[\"id\"]],\n",
    "                    }]\n",
    "                else:\n",
    "                    return [{\n",
    "                            \"text\": task_derive_question(thought),\n",
    "                            \"image\": None,\n",
    "                            \"caption\": None,\n",
    "                            \"category\": \"Create\",\n",
    "                            \"references\": [thought[\"id\"]],\n",
    "                        }]\n",
    "            elif thought[\"category\"] == \"Change\":\n",
    "                # visualize\n",
    "                # derive new question\n",
    "                if np.random.rand() < 0.5:\n",
    "                    caption, image = task_visualize(thought)\n",
    "                    return [{\n",
    "                        \"text\": caption,\n",
    "                        \"image\": image,\n",
    "                        \"caption\": caption,\n",
    "                        \"category\": \"Create\",\n",
    "                        \"references\": [thought[\"id\"]],\n",
    "                    }]\n",
    "                else:\n",
    "                    return [{\n",
    "                            \"text\": task_derive_question(thought),\n",
    "                            \"image\": None,\n",
    "                            \"caption\": None,\n",
    "                            \"category\": \"Create\",\n",
    "                            \"references\": [thought[\"id\"]],\n",
    "                        }]\n",
    "            elif thought[\"category\"] == \"Create\":\n",
    "                # knowledge\n",
    "                return [{\n",
    "                    \"text\": task_knowledge(thought),\n",
    "                    \"image\": None,\n",
    "                    \"caption\": None,\n",
    "                    \"category\": \"Information\",\n",
    "                    \"references\": [thought[\"id\"]],\n",
    "                }]\n",
    "        \n",
    "\n",
    "async def echo(websocket):\n",
    "    global server_running\n",
    "\n",
    "    async for message in websocket:\n",
    "        message = json.loads(message)\n",
    "        print(f'Client says: {message}')\n",
    "        if message['status'] == 'connected':\n",
    "            print(\"Client connected\")\n",
    "            await websocket.send(json.dumps({\"status\": \"connected\"}))\n",
    "\n",
    "        elif message['status'] == 'acknowledged':\n",
    "            # get a random thought from the db\n",
    "           \n",
    "            thoughts = await getResponse()\n",
    "\n",
    "            for thought in thoughts:\n",
    "                if thought[\"image\"]:\n",
    "                    # convert image to base64 string\n",
    "                    buffered = BytesIO()\n",
    "                    thought[\"image\"].save(buffered, format=\"JPEG\")\n",
    "                    img_str = base64.b64encode(buffered.getvalue())\n",
    "                    img_str = img_str.decode('utf-8')\n",
    "                else:\n",
    "                    img_str = None\n",
    "\n",
    "                # send the thoughtObj to the client as json data\n",
    "                try:\n",
    "                    await websocket.send(json.dumps({\"text\": thought[\"text\"], \"image\": img_str, \"caption\": thought[\"caption\"], \"category\": thought[\"category\"], \"generated\": True, \"in\": thought[\"references\"], \"status\": \"new\"}))\n",
    "                except:\n",
    "                    print(\"Client disconnected\")\n",
    "            \n",
    "            await websocket.send(json.dumps({\"status\": \"done\"}))\n",
    "            time.sleep(np.random.randint(10,30))\n",
    "\n",
    "        elif message['status'] == 'kill':\n",
    "            server_running = False\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with serve(echo, \"localhost\", 5000, ping_interval=None, ping_timeout=None):\n",
    "        # run until the server is killed\n",
    "        while server_running:\n",
    "            await asyncio.sleep(1)\n",
    "        print(\"Server killed\")\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
